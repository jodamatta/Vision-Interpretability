# Segment 02 — Activation Maximization

This segment focuses on **activation maximization** as a way of probing and visualizing what different parts of a convolutional neural network respond to. Building on the intuition developed in Segment 01, participants should approach this section as an exploratory exercise—choosing what to optimize, deciding how to visualize results, and reflecting on what those results suggest about internal representations.

In this segment, you will use **PyTorch** and the **Lucent library** (or an alternative if you find one that works better) to perform activation maximization on a pretrained vision model. For consistency across submissions, please use the **InceptionV1** model and generate activation maximizations for the **first 10 neurons of the `mixed4a` layer**.

As in the previous segment, aim to keep your notebook concise and focused. The goal is not to build a complete activation maximization pipeline, but to develop intuition for how these visualizations behave and how different choices influence their interpretability.

---

## Submission Instructions

Add your notebook to the `submissions/` folder for this segment.

**Notebook naming format:**
github-username__segment_2_activation_max.ipynb

