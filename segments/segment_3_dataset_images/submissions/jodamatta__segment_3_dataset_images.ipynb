{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1bc7181a",
   "metadata": {},
   "source": [
    "# Segment 3\n",
    "## Motivation\n",
    "In this notebook, we explore neuron-level interpretability in a classic convolutional neural network: InceptionV1. Our guiding questions are:\n",
    "\n",
    "- What kinds of visual patterns activate individual neurons?\n",
    "\n",
    "- Are these patterns reflected in real images from a dataset?\n",
    "\n",
    "- Can the synthetic visualizations help us build intuition about what natural images will activate strongly?\n",
    "\n",
    "To answer this, we will:\n",
    "\n",
    "1. Select neurons from an intermediate layer (mixed_4a)\n",
    "\n",
    "2. Generate activation-maximizing images for those neurons\n",
    "\n",
    "3. Search a dataset for real images that strongly activate the same neurons\n",
    "\n",
    "4. Visualize and analyze the resulting patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb6dd960",
   "metadata": {},
   "source": [
    "## Background Concepts\n",
    "### What is a \"neuron\" in a CNN?\n",
    "\n",
    "In convolutional networks, a neuron corresponds to one channel (feature map) in a convolutional layer. Each neuron responds to specific visual patterns such as edges or orientations (early layers), textures or shapes (middle layers) or object parts or concepts (later layers).\n",
    "\n",
    "### Why `mixed_4a`?\n",
    "\n",
    "InceptionV1â€™s mixed_4a layer sits roughly in the middle of the network, a sweet spot for studying emergent visual features. If it were too early, the detection would be mostly low-level edges, and if it were too late it would be highly abstract object concepts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45cf8db0",
   "metadata": {},
   "source": [
    "## Imports and Reproducibility\n",
    "We start by fixing all random seeds to make sure the results are reproducible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86261001",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "\n",
    "from lucent.optvis import render, param, transform, objectives\n",
    "from lucent.modelzoo import inceptionv1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45cf54a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808c027b",
   "metadata": {},
   "source": [
    "## The `Analyzer` Class\n",
    "To keep the notebook clean and modular, we wrap the full pipeline inside an `Analyzer`class. We use it to load the model, extract the activations, optimize images, search the dataset and visualize the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf862a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Analyzer:\n",
    "    \"\"\"\n",
    "    A utility class for neuron-level interpretability analysis\n",
    "    in InceptionV1 using activation maximization and dataset search.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, target_layer, device: str = 'cuda' if torch.cuda.is_available() else 'cpu'):\n",
    "        self.device = device\n",
    "        self.model = None\n",
    "        self.target_layer = target_layer\n",
    "        self.selected_neuron = None\n",
    "\n",
    "        # Dictionary used to store activations captured by hooks\n",
    "        self.activations = {}\n",
    "\n",
    "        self.load_model()\n",
    "\n",
    "        # Standard ImageNet preprocessing\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "\n",
    "    def load_model(self):\n",
    "        \"\"\"\n",
    "        Loads a pretrained InceptionV1 model\n",
    "        and sets it to evaluation mode.\n",
    "        \"\"\"\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model = inceptionv1(pretrained=True).to(device).eval()\n",
    "\n",
    "    def set_selected_neuron(self, neuron: int):\n",
    "        \"\"\"\n",
    "        Sets the neuron (channel index) to be analyzed.\n",
    "        \"\"\"\n",
    "        self.selected_neuron = neuron\n",
    "\n",
    "    def get_layer_info(self) -> Dict:\n",
    "        \"\"\"\n",
    "        Retrieves the module corresponding to the target layer name.\n",
    "        \"\"\"\n",
    "        target_module = None\n",
    "        for name, module in self.model.named_modules():\n",
    "            if name == self.target_layer:\n",
    "                target_module = module\n",
    "                break\n",
    "\n",
    "        if target_module is None:\n",
    "            raise ValueError(f\"Layer {self.target_layer} not found in model\")\n",
    "\n",
    "        return {\n",
    "            'name': self.target_layer,\n",
    "            'module': target_module\n",
    "        }\n",
    "\n",
    "    # As we've seen in previous segments, activation maximization is a technique used to generate input images that maximize the activation of specific neurons within a neural network. \n",
    "    # This is typically done through gradient-based optimization, where we start with a random image and iteratively adjust it to increase the activation of the target neuron. \n",
    "    # The resulting images can provide insights into what features or patterns the neuron is responsive to, helping us understand the internal workings of the model.\n",
    "\n",
    "    def activation_maximization(self, neuron, steps: int = 512, lr: float = 0.05) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Generates an image that maximally activates a given neuron\n",
    "        using gradient-based optimization.\n",
    "        \"\"\"\n",
    "        self.set_selected_neuron(neuron)\n",
    "\n",
    "        # Objective: maximize a specific channel in a specific layer\n",
    "        obj = objectives.channel(self.target_layer, self.selected_neuron)\n",
    "\n",
    "        # Small transformations prevent the optimization from producing high-frequency artifacts, and encourage more interpretable patterns.\n",
    "        transform_list = [\n",
    "            transform.pad(12),\n",
    "            transform.jitter(8),\n",
    "            transform.random_scale([0.9, 0.95, 1.05, 1.1]),\n",
    "            transform.random_rotate([-5, -4, -3, -2, -1, 0, 1, 2, 3, 4, 5]),\n",
    "            transform.jitter(2)\n",
    "        ]\n",
    "\n",
    "        # Using an FFT-based parameterization biases the optimization towards more natural-looking structures.\n",
    "        def param_f(self, lr: float = 0.05):\n",
    "            return param.image(224, fft=True, decorrelate=True, lr=lr)\n",
    "        \n",
    "        result = render.render_vis(\n",
    "            self.model,\n",
    "            obj,\n",
    "            param_f=param_f,\n",
    "            transforms=transform_list,\n",
    "            thresholds=(steps,),\n",
    "            show_inline=False\n",
    "        )\n",
    "\n",
    "        optimized_image = result[0]\n",
    "        return optimized_image\n",
    "    \n",
    "    # To measure neuron responses to real images, we attach a forward hook to the target layer.\n",
    "    def setup_activation_hook(self):\n",
    "        \"\"\"\n",
    "        Registers a forward hook to capture activations\n",
    "        from the target layer during inference.\n",
    "        \"\"\"\n",
    "        def hook_fn(module, input, output):\n",
    "            self.activations[self.target_layer] = output.detach()\n",
    "\n",
    "        for name, module in self.model.named_modules():\n",
    "            if name == self.target_layer:\n",
    "                module.register_forward_hook(hook_fn)\n",
    "                break\n",
    "\n",
    "    def get_neuron_activation(self, image: torch.Tensor) -> float:\n",
    "        \"\"\"\n",
    "        Computes the mean activation value of the selected neuron\n",
    "        for a given image.\n",
    "        \"\"\"\n",
    "        with torch.no_grad():\n",
    "            if len(image.shape) == 3:\n",
    "                image = image.unsqueeze(0)\n",
    "\n",
    "            image = image.to(self.device)\n",
    "            _ = self.model(image)\n",
    "\n",
    "            layer_activation = self.activations[self.target_layer]\n",
    "            neuron_activation = layer_activation[0, self.selected_neuron]\n",
    "\n",
    "            # Average over spatial dimensions\n",
    "            return neuron_activation.mean().item()\n",
    "        \n",
    "    # Instead of a single number, we can also inspect where the neuron fires spatially.\n",
    "    def get_neuron_activation_map(self, image: torch.Tensor) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Returns a normalized spatial activation map\n",
    "        for the selected neuron.\n",
    "        \"\"\"\n",
    "        with torch.no_grad():\n",
    "            if len(image.shape) == 3:\n",
    "                image = image.unsqueeze(0)\n",
    "\n",
    "            image = image.to(self.device)\n",
    "            _ = self.model(image)\n",
    "\n",
    "            activation_map = self.activations[self.target_layer][0, self.selected_neuron]\n",
    "            activation_map = activation_map.cpu().numpy()\n",
    "\n",
    "            # Normalize for visualization\n",
    "            if activation_map.max() > activation_map.min():\n",
    "                activation_map = (activation_map - activation_map.min()) / (\n",
    "                    activation_map.max() - activation_map.min()\n",
    "                )\n",
    "\n",
    "            return activation_map\n",
    "        \n",
    "    # We can now search the dataset to find real images that strongly activate the neuron.\n",
    "    def find_highly_activating_images(\n",
    "        self,\n",
    "        num_samples: int = 1000,\n",
    "        top_k: int = 10,\n",
    "        split: str = \"train\",\n",
    "        dataset_root: str = \"data/imagenette2-320\"\n",
    "    ) -> List[Tuple[Image.Image, float]]:\n",
    "        \n",
    "        self.setup_activation_hook()\n",
    "        split = \"val\" if split in (\"validation\", \"valid\", \"test\", \"val\") else \"train\"\n",
    "        split_path = Path(dataset_root) / split\n",
    "\n",
    "        transform = transforms.Compose([\n",
    "            transforms.Resize(256),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225],\n",
    "            ),\n",
    "        ])\n",
    "\n",
    "        dataset = ImageFolder(str(split_path), transform=transform)\n",
    "\n",
    "        if len(dataset) > num_samples:\n",
    "            indices = random.sample(range(len(dataset)), num_samples)\n",
    "            dataset = Subset(dataset, indices)\n",
    "\n",
    "        dataloader = DataLoader(dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "        image_activations = []\n",
    "\n",
    "        for image, _ in dataloader:\n",
    "            activation_value = self.get_neuron_activation(image)\n",
    "            activation_map = self.get_neuron_activation_map(image)\n",
    "\n",
    "            image_activations.append((image, activation_value, activation_map))\n",
    "\n",
    "        image_activations.sort(key=lambda x: x[1], reverse=True)\n",
    "        return image_activations[:top_k]\n",
    "    \n",
    "    # This step performs simple descriptive analysis (color statistics, constrast heuristics and pattern labels)\n",
    "    def analyze_patterns(self, optimized_image: torch.Tensor,\n",
    "                        top_images: List[Tuple[Image.Image, float, np.ndarray]]) -> Dict:\n",
    "\n",
    "        analysis = {\n",
    "            'neuron_id': self.selected_neuron,\n",
    "            'layer': self.target_layer,\n",
    "            'optimization_result': optimized_image,\n",
    "            'top_activating_images': top_images,\n",
    "            'patterns_detected': [],\n",
    "            'color_analysis': {},\n",
    "            'texture_analysis': {}\n",
    "        }\n",
    "\n",
    "        opt_img_pil = transforms.ToPILImage()(optimized_image.squeeze(0))\n",
    "\n",
    "        opt_img_array = np.array(opt_img_pil)\n",
    "        mean_color = np.mean(opt_img_array, axis=(0, 1))\n",
    "        std_color = np.std(opt_img_array, axis=(0, 1))\n",
    "\n",
    "        analysis['color_analysis']['optimized_image'] = {\n",
    "            'mean_rgb': mean_color.tolist(),\n",
    "            'std_rgb': std_color.tolist()\n",
    "        }\n",
    "\n",
    "        top_image_colors = []\n",
    "        for img, activation, _ in top_images[:5]:\n",
    "            img_array = np.array(img)\n",
    "            img_mean = np.mean(img_array, axis=(0, 1))\n",
    "            top_image_colors.append(img_mean.tolist())\n",
    "\n",
    "        analysis['color_analysis']['top_images'] = top_image_colors\n",
    "\n",
    "        patterns = []\n",
    "        if np.std(opt_img_array) > 50:\n",
    "            patterns.append(\"High contrast/texture\")\n",
    "        if np.mean(mean_color) > 150:\n",
    "            patterns.append(\"Bright colors\")\n",
    "        elif np.mean(mean_color) < 100:\n",
    "            patterns.append(\"Dark colors\")\n",
    "\n",
    "        analysis['patterns_detected'] = patterns\n",
    "\n",
    "        return analysis\n",
    "\n",
    "    # This step creates visualizations in a structured manner.\n",
    "    def visualize_results(self, analysis: Dict, save_dir: str = 'results'):\n",
    "\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "        top_images = analysis['top_activating_images']\n",
    "        n_images = min(len(top_images), 10)\n",
    "\n",
    "        fig, axes = plt.subplots(n_images + 1, 2, figsize=(15, 4 * (n_images + 1)))\n",
    "        fig.suptitle(f'Neuron {self.selected_neuron} Analysis - Layer {self.target_layer}',\n",
    "                    fontsize=16, fontweight='bold')\n",
    "\n",
    "        opt_img = analysis['optimization_result']\n",
    "        if isinstance(opt_img, torch.Tensor):\n",
    "            opt_img_display = opt_img.squeeze(0).permute(1, 2, 0).detach().cpu().numpy()\n",
    "        else:\n",
    "            opt_img_display = opt_img.squeeze() if opt_img.ndim == 4 else opt_img\n",
    "            if opt_img_display.ndim == 3 and opt_img_display.shape[0] == 3:\n",
    "                opt_img_display = np.transpose(opt_img_display, (1, 2, 0))\n",
    "\n",
    "        opt_img_display = np.clip(opt_img_display, 0, 1)\n",
    "\n",
    "        axes[0, 0].imshow(opt_img_display)\n",
    "        axes[0, 0].set_title('Activation Maximization\\nResult', fontweight='bold')\n",
    "        axes[0, 0].axis('off')\n",
    "        axes[0, 1].axis('off')\n",
    "\n",
    "        for i, (img, activation, activation_map) in enumerate(top_images[:n_images]):\n",
    "            row = i + 1\n",
    "\n",
    "            axes[row, 0].imshow(img)\n",
    "            axes[row, 0].set_title(f'Top {i+1} Image\\nActivation: {activation:.3f}', fontsize=10)\n",
    "            axes[row, 0].axis('off')\n",
    "\n",
    "            im = axes[row, 1].imshow(activation_map, cmap='viridis', interpolation='nearest')\n",
    "            axes[row, 1].set_title(f'Activation Map\\nMax: {activation_map.max():.3f}', fontsize=10)\n",
    "            axes[row, 1].axis('off')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{save_dir}/neuron_{self.selected_neuron}_analysis_with_activations.png',\n",
    "                   dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "\n",
    "    # Finally, we tie everything together\n",
    "    def run_complete_analysis(self,\n",
    "                              neuron: int = 0,\n",
    "                              num_samples: int = 1000,\n",
    "                              top_k: int = 10,\n",
    "                              optim_steps: int = 512) -> Dict:\n",
    "\n",
    "        print(\"\\nStep 1: Performing activation maximization...\")\n",
    "        optimized_image = self.activation_maximization(neuron, steps=optim_steps)\n",
    "\n",
    "        print(\"\\nStep 2: Finding highly activating dataset images...\")\n",
    "        top_images = self.find_highly_activating_images(\n",
    "            num_samples=num_samples,\n",
    "            top_k=top_k\n",
    "        )\n",
    "\n",
    "        print(\"\\nStep 3: Analyzing patterns and features...\")\n",
    "        analysis = self.analyze_patterns(optimized_image, top_images)\n",
    "\n",
    "        print(\"\\nStep 4: Creating visualizations...\")\n",
    "        self.visualize_results(analysis, save_dir=\"activating0\")\n",
    "\n",
    "        return analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445e7afc",
   "metadata": {},
   "source": [
    "## Example with one neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8847d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = Analyzer(\"mixed4a\")\n",
    "\n",
    "results = analyzer.run_complete_analysis(\n",
    "    neuron=1,\n",
    "    num_samples=500,\n",
    "    top_k=10,\n",
    "    optim_steps=512\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424fb053",
   "metadata": {},
   "source": [
    "## What to Look For in the Results\n",
    "As you explore different neurons, ask:\n",
    "\n",
    "- Does the activation maximization and the real images share visual motifs?\n",
    "\n",
    "- Is the neuron sensitive to color, texture, shape, or structure?\n",
    "\n",
    "- Are activation maps localized or diffuse?\n",
    "\n",
    "Here are the 10 images that activate the most for the first 10 neurons of the `mixed_4a` layer. Each neuron is analyzed independently, and the results are stored in a dictionary for inspection. \n",
    "\n",
    "Try to identify why the neuron activated highly for this image, and where the pattern shows up!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1534ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = Analyzer(target_layer=\"mixed_4a\")\n",
    "\n",
    "all_results = {}\n",
    "\n",
    "for neuron_id in range(1, 11):\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Analyzing neuron {neuron_id} in layer mixed_4a\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    analysis = analyzer.run_complete_analysis(\n",
    "        neuron=neuron_id,\n",
    "        num_samples=500,\n",
    "        top_k=10,\n",
    "        optim_steps=512\n",
    "    )\n",
    "\n",
    "    all_results[neuron_id] = analysis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-lucent (3.10.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
